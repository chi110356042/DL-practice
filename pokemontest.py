# -*- coding: utf-8 -*-
"""pokemontest.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1uI7FfUN4_V-1mVQiJp0kM5GiULG_V4DG
"""

from google.colab import drive
drive.mount('/content/drive', force_remount=True)

FOLDERNAME = 'poketest'
assert FOLDERNAME is not None, "[!] Enter the foldername."

import sys
sys.path.append('/content/drive/My Drive/{}'.format(FOLDERNAME))

#input_data= '/content/drive/MyDrive/ai_final/'

import tensorflow as tf
from tensorflow import keras
from keras.models import Sequential
from keras.layers import Dense, Dropout, Activation, Flatten,Conv2D,MaxPooling2D
from keras.utils import np_utils
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import pandas as pd
import numpy as np
import os,cv2
import random

def get_images(directory):
    Images=[]
    Labels=[]
    label=0
    
    for labels in os.listdir(directory):
        if labels == 'Zubat':
            label = 0
        elif labels == 'Zapdos':
            label = 1
        elif labels == 'Wigglytuff':
            label = 2
        elif labels == 'Weezing':
            label = 3
        elif labels == 'Weepinbell':
            label = 4
        
        for images_file in os.listdir(directory+labels):
            image=cv2.imread(directory+labels+r'/'+images_file) #read the images
            image=cv2.resize(image,(150,150))
            Images.append(image)
            Labels.append(label)
    
    #return random.shuffle(Images,Labels)
    return Images,Labels

def get_classlabel(class_code):
    labels={0:'Zubat',1:'Zapdos',2:'Wigglytuff',3:'Weezing',4:'Weepinbell'}
    return labels[class_code]

Images,Labels=get_images('/content/drive/My Drive/poketest/')
Images=np.array(Images)
Labels=np.array(Labels)

permutation = np.random.permutation(Labels.shape[0])
shuffled_Images =Images[permutation, :, :, :]
shuffled_Labels =Labels[permutation]

f,ax=plt.subplots(5,5)
f.subplots_adjust(0,0,3,3)
for i in range(0,5,1):
  for j in range(0,5,1):
    rnd_number=random.randint(0,len(Images))
    ax[i,j].imshow(Images[rnd_number])
    ax[i,j].set_title(get_classlabel(Labels[rnd_number]))
    ax[i,j].axis('off')

print(Images.shape)
print(Labels.shape)
print(type(Images))
print(type(Labels))

"""**First model**"""

model = Sequential()

model.add(Conv2D(200,kernel_size=(3,3),activation='relu',input_shape=(150,150,3)))
model.add(Conv2D(180,kernel_size=(3,3),activation='relu'))
model.add(MaxPooling2D(5,5))
model.add(Conv2D(140,kernel_size=(3,3),activation='relu'))
model.add(Conv2D(100,kernel_size=(3,3),activation='relu'))
model.add(Conv2D(50,kernel_size=(3,3),activation='relu'))
model.add(MaxPooling2D(5,5))
model.add(Flatten())
model.add(Dense(180,activation='relu'))
model.add(Dense(100,activation='relu'))
model.add(Dense(50,activation='relu'))
model.add(Dropout(0.5))
model.add(Dense(5,activation='sigmoid'))
model.summary()

optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)
model.compile(optimizer,loss='sparse_categorical_crossentropy',metrics=['acc'])

trained=model.fit(Images,Labels,epochs=10,batch_size=32,validation_split=0.3)

trained=model.fit(shuffled_Images,shuffled_Labels,epochs=10,batch_size=32,validation_split=0.3)

#plot model acc
plt.rcParams['figure.figsize']=(6,4)
plt.plot(trained.history['acc'],label='training_acc')
plt.plot(trained.history['val_acc'],label='val_acc')
plt.legend(loc='upper right')
plt.show()
plt.close()

#plot model loss
plt.rcParams['figure.figsize']=(6,4)
plt.plot(trained.history['loss'],label='training_loss')
plt.plot(trained.history['val_loss'],label='val_loss')
plt.legend(loc='upper right')
plt.show()
plt.close()

test_images,test_labels=get_images('/content/drive/My Drive/poketest2/')
test_images=np.array(test_images)
test_labels=np.array(test_labels)
model.evaluate(test_images,test_labels,verbose=1)

"""
**Second model**


*   learning_rate改為0.0001
*   batch_size改為64
*   輸出層activation改為softmax




"""

model = Sequential()

model.add(Conv2D(200,kernel_size=(3,3),activation='relu',input_shape=(150,150,3)))
model.add(Conv2D(180,kernel_size=(3,3),activation='relu'))
model.add(MaxPooling2D(5,5))
model.add(Conv2D(140,kernel_size=(3,3),activation='relu'))
model.add(Conv2D(100,kernel_size=(3,3),activation='relu'))
model.add(Conv2D(50,kernel_size=(3,3),activation='relu'))
model.add(MaxPooling2D(5,5))
model.add(Flatten())
model.add(Dense(180,activation='relu'))
model.add(Dense(100,activation='relu'))
model.add(Dense(50,activation='relu'))
model.add(Dropout(0.5))
model.add(Dense(5,activation='softmax'))
model.summary()

optimizer = tf.keras.optimizers.Adam(learning_rate=0.0001)
model.compile(optimizer,loss='sparse_categorical_crossentropy',metrics=['acc'])

trained=model.fit(Images,Labels,epochs=10,batch_size=64,validation_split=0.3)

#plot model acc
plt.rcParams['figure.figsize']=(6,4)
plt.plot(trained.history['acc'],label='training_acc')
plt.plot(trained.history['val_acc'],label='val_acc')
plt.legend(loc='upper right')
plt.show()
plt.close()

#plot model loss
plt.rcParams['figure.figsize']=(6,4)
plt.plot(trained.history['loss'],label='training_loss')
plt.plot(trained.history['val_loss'],label='val_loss')
plt.legend(loc='upper right')
plt.show()
plt.close()

test_images,test_labels=get_images('/content/drive/My Drive/poketest2/')
test_images=np.array(test_images)
test_labels=np.array(test_labels)
model.evaluate(test_images,test_labels,verbose=1)

"""**Third model**



*   Conv2D改為６層



"""

model = Sequential()

model.add(Conv2D(200,kernel_size=(3,3),activation='relu',input_shape=(150,150,3)))
model.add(Conv2D(180,kernel_size=(3,3),activation='relu'))
model.add(Conv2D(100,kernel_size=(3,3),activation='relu'))
model.add(MaxPooling2D(5,5))
model.add(Conv2D(140,kernel_size=(3,3),activation='relu'))
model.add(Conv2D(100,kernel_size=(3,3),activation='relu'))
model.add(Conv2D(50,kernel_size=(3,3),activation='relu'))
model.add(MaxPooling2D(5,5))
model.add(Flatten())
model.add(Dense(180,activation='relu'))
model.add(Dense(100,activation='relu'))
model.add(Dense(50,activation='relu'))
model.add(Dropout(0.5))
model.add(Dense(5,activation='softmax'))
model.summary()

optimizer = tf.keras.optimizers.Adam(learning_rate=0.0001)
model.compile(optimizer,loss='sparse_categorical_crossentropy',metrics=['acc'])

trained=model.fit(Images,Labels,epochs=10,batch_size=64,validation_split=0.3)

#plot model acc
plt.rcParams['figure.figsize']=(6,4)
plt.plot(trained.history['acc'],label='training_acc')
plt.plot(trained.history['val_acc'],label='valacc')
plt.legend(loc='upper right')
plt.show()
plt.close()

#plot model loss
plt.rcParams['figure.figsize']=(6,4)
plt.plot(trained.history['loss'],label='training_loss')
plt.plot(trained.history['val_loss'],label='val_loss')
plt.legend(loc='upper right')
plt.show()
plt.close()

test_images,test_labels=get_images('/content/drive/My Drive/poketest2/')
test_images=np.array(test_images)
test_labels=np.array(test_labels)
model.evaluate(test_images,test_labels,verbose=1)

"""**比較三種方式：**"""